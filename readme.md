## Stemming, lemmatization and tokenization:
[nlp_basic.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/nlp_basics.ipynb)
## Word embedding :
[word_embedding.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/word_embedding.ipynb) 
(python keras)
## Text spam classification using TFIDF : 
[spam_classification.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/spam_classification.ipynb)
## Text spam classification using word embedding and LSTM : 
[spam_classification_word_embedding.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/spam_classification_word_embedding.ipynb)
## Saving and loading Keras models :
[tensorflow doc](https://www.tensorflow.org/guide/keras/serialization_and_saving) , [spam_classification_word_embedding.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/spam_classification_word_embedding.ipynb)
## Transformer sentiment analysis Hugging face :
[transformer_classification_hugging_face.ipynb](https://github.com/sarasafaee/nlp_basics/blob/main/transformer_classification_hugging_face.ipynb)

## Attention mechanism :
- what is it ? It allows models to focus on the most relevant parts of an input sequence when making predictions.
Important article -> [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)

## Transformers : 
- what are they ? Transformers are a deep learning architecture in NLP that uses the attention mechanism to analyze relationships between words in a sentence, enabling them to excel at various tasks.
Important article -> [Attention Is All You Need
](https://arxiv.org/abs/1706.03762)

## Sentiment analysis : 
[i=Important article about multilingual language model for sentiment analysis](https://aclanthology.org/2022.lrec-1.27/)
